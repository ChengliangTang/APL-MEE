{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This script evaluates the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os, cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.path import Path\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "time_start = datetime.now()\n",
    "## load submission csv\n",
    "SPECIES = 'palm' ## 'palm' or 'cec'\n",
    "dat_sub = pd.read_csv('../data/MTurk/MTurk_' + SPECIES + '.csv')\n",
    "## load human reference\n",
    "href_array = []\n",
    "for file_name in os.listdir('../output/mref/' + SPECIES + '/'):\n",
    "    if file_name.endswith('.csv') == False:\n",
    "        continue\n",
    "    href = pd.read_csv('../output/mref/' + SPECIES + '/' + file_name, index_col=0)\n",
    "    href_resize = cv2.resize(np.array(href, dtype=np.uint8), (1000, 1000))\n",
    "    href_array.append(href_resize)\n",
    "href_array = np.array(href_array)\n",
    "print('Time for loading data:', datetime.now() - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function definition\n",
    "## function for transforming polygon to mask\n",
    "def poly2mask(nx, ny, poly_verts):\n",
    "    # Create vertex coordinates for each grid cell...\n",
    "    # (<0,0> is at the top left of the grid in this system)\n",
    "    x, y = np.meshgrid(np.arange(nx), np.arange(ny))\n",
    "    x, y = x.flatten(), y.flatten()\n",
    "    points = np.vstack((x,y)).T\n",
    "    path = Path(poly_verts)\n",
    "    grid = path.contains_points(points)\n",
    "    grid = grid.reshape((ny,nx))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the annotators, calculate leave-one-out TP, FP, TN, FN, Number of Assignments\n",
    "url_arr = np.array(dat_sub['Input.img_url'])\n",
    "status_arr = np.array(dat_sub['AssignmentStatus'])\n",
    "work_list = np.unique(dat_sub['WorkerId'])\n",
    "print('There are', len(work_list), 'users.')\n",
    "nums_dict = {}\n",
    "tp_dict = {}\n",
    "fp_dict = {}\n",
    "tn_dict = {}\n",
    "fn_dict = {}\n",
    "val_dict = {}\n",
    "time_start = datetime.now()\n",
    "print('Start time:', time_start)\n",
    "n_done = 1\n",
    "for work_id in work_list:\n",
    "    if n_done % 5 == 0:\n",
    "        print('Task Finished:', \"{:.2%}\".format(n_done / len(work_list)), end=\"\\r\")\n",
    "    loc = np.where(dat_sub['WorkerId'] == work_id)[0]\n",
    "    nums_dict[work_id] = 0\n",
    "    tp_list = []\n",
    "    tn_list = []\n",
    "    fp_list = []\n",
    "    fn_list = []\n",
    "    num_acpt = 0\n",
    "    for i in loc:\n",
    "        img_url = url_arr[i]\n",
    "        if status_arr[i] == 'Approved':\n",
    "            num_acpt += 1\n",
    "        img_id = int(img_url[-8:-4]) - 1\n",
    "        nums_dict[work_id] += 1\n",
    "        ## obtain the estimation of this human annotator\n",
    "        palm_mat = np.zeros([1000, 1000])\n",
    "        polyString = dat_sub['Answer.coordinates'][i]\n",
    "        polyString = polyString.replace('[', '')\n",
    "        polyString = polyString.replace(']', '')\n",
    "        polyString = polyString.replace('\"x\":', '')\n",
    "        polyString = polyString.replace(',\"y\":', ';')\n",
    "        polyString = polyString.replace(',', '')\n",
    "        polyList = polyString.split('{-1;-1}')\n",
    "        polyList.pop()\n",
    "        for polyGon in polyList:\n",
    "            elementList = polyGon.split('}{')\n",
    "            ## transform element list into integers\n",
    "            for i in range(len(elementList)):\n",
    "                element = elementList[i].replace('{', '')\n",
    "                element = element.replace('}', '')\n",
    "                (x, y) = element.split(';')\n",
    "                x = int(float(x)) - 1\n",
    "                y = int(float(y)) - 1\n",
    "                elementList[i] = (max([0, x]), max([0, y]))\n",
    "            polyMask = poly2mask(1000, 1000, elementList)\n",
    "            palm_mat[polyMask == True] = 1\n",
    "        palm_mat = cv2.resize(np.array(palm_mat, dtype=np.uint8), (100, 100))\n",
    "        pic_num = img_id // 100\n",
    "        res_num = img_id % 100\n",
    "        r = res_num // 10\n",
    "        c = res_num - r * 10\n",
    "        r1 = r * 100\n",
    "        r2 = r1 + 100\n",
    "        c1 = c * 100\n",
    "        c2 = c1 + 100\n",
    "        tp = palm_mat[href_array[pic_num][r1:r2, c1:c2] == 1].sum()\n",
    "        fp = palm_mat[href_array[pic_num][r1:r2, c1:c2] == 0].sum()\n",
    "        tn = (1 - palm_mat[href_array[pic_num][r1:r2, c1:c2] == 0]).sum()\n",
    "        fn = (1 - palm_mat[href_array[pic_num][r1:r2, c1:c2] == 1]).sum()\n",
    "        tp_list.append(tp)\n",
    "        fp_list.append(fp)\n",
    "        tn_list.append(tn)\n",
    "        fn_list.append(fn)\n",
    "    val_dict[work_id] = num_acpt / len(loc)\n",
    "    tp_dict[work_id] = tp_list\n",
    "    fp_dict[work_id] = fp_list\n",
    "    tn_dict[work_id] = tn_list\n",
    "    fn_dict[work_id] = fn_list\n",
    "    n_done += 1\n",
    "time_lapse = datetime.now() - time_start\n",
    "print('This part took time:', time_lapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate the TPR, FPR and nums_dict for each user\n",
    "nums_list = []\n",
    "IoU_list = []\n",
    "acc_list = []\n",
    "TPR_list = []\n",
    "FPR_list = []\n",
    "prec_list = []\n",
    "rec_list = []\n",
    "val_list = []\n",
    "for work_id in nums_dict.keys():\n",
    "    if nums_dict[work_id] == 0:\n",
    "        continue\n",
    "    else:\n",
    "        val_list.append(val_dict[work_id])\n",
    "        nums_list.append(nums_dict[work_id])\n",
    "        ## calculate IoU\n",
    "        if np.sum(tp_dict[work_id]) + np.sum(fp_dict[work_id]) + np.sum(fn_dict[work_id]) > 0:\n",
    "            IoU = np.sum(tp_dict[work_id]) / (np.sum(tp_dict[work_id]) + np.sum(fp_dict[work_id]) + np.sum(fn_dict[work_id]))\n",
    "        else:\n",
    "            IoU = 0\n",
    "        ## calculate Accuracy\n",
    "        acc = (np.sum(tp_dict[work_id]) + np.sum(tn_dict[work_id])) / (np.sum(tp_dict[work_id]) + np.sum(fp_dict[work_id]) + np.sum(fn_dict[work_id]) + np.sum(tn_dict[work_id]))\n",
    "        ## calculate TPR\n",
    "        if (np.sum(tp_dict[work_id]) + np.sum(fn_dict[work_id])) > 0:\n",
    "            TPR = np.sum(tp_dict[work_id]) / (np.sum(tp_dict[work_id]) + np.sum(fn_dict[work_id]))\n",
    "        else:\n",
    "            TPR = 0\n",
    "        ## calculate FPR\n",
    "        FPR = np.sum(fp_dict[work_id]) / (np.sum(fp_dict[work_id]) + np.sum(tn_dict[work_id]))\n",
    "        ## calculate precision\n",
    "        if (np.sum(fp_dict[work_id]) + np.sum(tp_dict[work_id])) > 0:\n",
    "            prec = np.sum(tp_dict[work_id]) / (np.sum(fp_dict[work_id]) + np.sum(tp_dict[work_id]))\n",
    "        else:\n",
    "            prec = 0\n",
    "        ## calculate recall\n",
    "        if (np.sum(fn_dict[work_id]) + np.sum(tp_dict[work_id])) > 0:\n",
    "            rec = np.sum(tp_dict[work_id]) / (np.sum(fn_dict[work_id]) + np.sum(tp_dict[work_id]))\n",
    "        else:\n",
    "            rec = 0\n",
    "        ## update lists\n",
    "        IoU_list.append(IoU)\n",
    "        acc_list.append(acc)\n",
    "        TPR_list.append(TPR)\n",
    "        FPR_list.append(FPR)\n",
    "        prec_list.append(prec)\n",
    "        rec_list.append(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# evaluate the predictions\n",
    "## load APL predictions\n",
    "preds_array = []\n",
    "k = np.ones((10, 10)) / 100 ## weight kernel ==> average predictions on overlapped areas\n",
    "for file_name in os.listdir('../output/npy/npy_20_25/'):\n",
    "    if file_name.endswith('.npy') == False:\n",
    "        continue\n",
    "    preds = np.load('../output/npy/npy_20_25/' + file_name)\n",
    "    preds_new = np.zeros((1000, 1000, preds.shape[2]))\n",
    "    for i in range(preds.shape[2]):\n",
    "        preds_new[:, :, i] = cv2.resize(preds[:, :, i], (1000, 1000))\n",
    "        preds_new[:, :, i] = ndimage.convolve(preds_new[:, :, i], k, mode='constant', cval=0.0)\n",
    "    preds_array.append(preds_new)\n",
    "preds_array = np.array(preds_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load Basic predictions\n",
    "preds_basic = []\n",
    "k = np.ones((10, 10)) / 100 ## weight kernel ==> average predictions on overlapped areas\n",
    "for file_name in os.listdir('../output/npy/npy_Basic/'):\n",
    "    if file_name.endswith('.npy') == False:\n",
    "        continue\n",
    "    preds = np.load('../output/npy/npy_Basic/' + file_name)\n",
    "    preds_new = np.zeros((1000, 1000, preds.shape[2]))\n",
    "    for i in range(preds.shape[2]):\n",
    "        preds_new[:, :, i] = cv2.resize(preds[:, :, i], (1000, 1000))\n",
    "        preds_new[:, :, i] = ndimage.convolve(preds_new[:, :, i], k, mode='constant', cval=0.0)\n",
    "    preds_basic.append(preds_new)\n",
    "preds_basic = np.array(preds_basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve\n",
    "## vectorize\n",
    "testy = np.array([href_array[i] for i in range(3)], dtype=np.float).flatten()\n",
    "probs_apl = np.array([preds_array[i, :, :, 0] for i in range(3)]).flatten()\n",
    "probs_basic = np.array([preds_basic[i, :, :, 0] for i in range(3)]).flatten()\n",
    "## calculate the ROC curves\n",
    "fpr_palm, tpr_palm, _ = roc_curve(testy, probs_apl)\n",
    "roc_auc_palm = auc(fpr_palm, tpr_palm)\n",
    "fpr_cec, tpr_cec, _ = roc_curve(testy, probs_basic)\n",
    "roc_auc_cec = auc(fpr_cec, tpr_cec)\n",
    "## plot the figure\n",
    "lw = 2\n",
    "font_size = 15\n",
    "normalize = mcolors.Normalize(vmin=0, vmax=1)\n",
    "colormap = cm.coolwarm\n",
    "scalarmappaple = cm.ScalarMappable(norm=normalize, cmap=colormap)\n",
    "scalarmappaple.set_array([])\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(FPR_list, TPR_list, s = np.sqrt(nums_list)*3, label='Annotators', c= colormap(normalize(val_list)))\n",
    "plt.plot(fpr_palm, tpr_palm, color='darkgreen',\n",
    "         lw=lw, label='APL (AUC = %0.2f)' % roc_auc_palm)\n",
    "plt.plot(fpr_cec, tpr_cec, color='darkorange',\n",
    "         lw=lw, label='Basic (AUC = %0.2f)' % roc_auc_cec)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=font_size)\n",
    "plt.ylabel('True Positive Rate', fontsize=font_size)\n",
    "#plt.title('ROC curve for Palm')\n",
    "plt.legend(loc=\"lower right\", fontsize=font_size-1)\n",
    "plt.tick_params(labelsize=font_size)\n",
    "plt.colorbar(scalarmappaple)\n",
    "plt.savefig('../output/figs/palm_ROC.png', bbox_inches='tight')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_precision_APL, lr_recall_APL, _ = precision_recall_curve(testy, probs_apl)\n",
    "lr_precision_Basic, lr_recall_Basic, _ = precision_recall_curve(testy, probs_basic)\n",
    "lw = 2\n",
    "# plot the precision-recall curves\n",
    "no_skill = len(testy[testy==1]) / len(testy)\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', lw=lw, color='navy')\n",
    "plt.plot([0, lr_recall_APL[lr_recall_APL > 0.01][-1]], [1, lr_precision_APL[lr_recall_APL>0.01][-1]], lw = lw, color='darkgreen')\n",
    "plt.plot(lr_recall_APL[lr_recall_APL > 0.01], lr_precision_APL[lr_recall_APL > 0.01], lw = lw, label='APL', color='darkgreen')\n",
    "plt.plot([0, lr_recall_Basic[lr_recall_Basic > 0.01][-1]], [1, lr_precision_Basic[lr_recall_Basic>0.01][-1]], lw = lw, color='darkorange')\n",
    "plt.plot(lr_recall_Basic[lr_recall_Basic > 0.01], lr_precision_Basic[lr_recall_Basic > 0.01], lw = lw, label='Basic', color='darkorange')\n",
    "plt.scatter(rec_list, prec_list, s = np.sqrt(nums_list)*3, label='Annotators', c= colormap(normalize(val_list)))\n",
    "# axis labels\n",
    "plt.xlabel('Recall', fontsize=font_size)\n",
    "plt.ylabel('Precision', fontsize=font_size)\n",
    "plt.colorbar(scalarmappaple)\n",
    "plt.tick_params(labelsize=font_size)\n",
    "# show the legend\n",
    "plt.legend(loc='lower right', fontsize=font_size)\n",
    "plt.savefig('../output/figs/palm_prec.png', bbox_inches='tight')  \n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut-off selection \n",
    "n_thresh = 100\n",
    "thresh_array = np.zeros(n_thresh)\n",
    "IoU_array_apl = np.zeros(n_thresh)\n",
    "acc_array_apl = np.zeros(n_thresh)\n",
    "IoU_array_basic = np.zeros(n_thresh)\n",
    "acc_array_basic = np.zeros(n_thresh)\n",
    "for i in range(n_thresh):\n",
    "    thresh_apl = np.quantile(probs_apl, i / n_thresh)\n",
    "    ## for apl\n",
    "    y_apl = probs_apl > thresh_apl\n",
    "    n_inter_apl = np.sum(y_apl * testy)\n",
    "    n_union_apl = np.sum((y_apl + testy) > 0)\n",
    "    n_true_apl = np.sum(y_apl * testy) + np.sum((1-y_apl) * (1-testy))\n",
    "    thresh_array[i] = i / n_thresh\n",
    "    IoU_array_apl[i] = n_inter_apl / n_union_apl\n",
    "    acc_array_apl[i] = n_true_apl / len(testy)\n",
    "    ## for basic\n",
    "    thresh_basic = np.quantile(probs_basic, i / n_thresh)\n",
    "    y_basic = probs_basic > thresh_basic\n",
    "    n_inter_basic = np.sum(y_basic * testy)\n",
    "    n_union_basic = np.sum((y_basic + testy) > 0)\n",
    "    n_true_basic = np.sum(y_basic * testy) + np.sum((1-y_basic) * (1-testy))\n",
    "    IoU_array_basic[i] = n_inter_basic / n_union_basic\n",
    "    acc_array_basic[i] = n_true_basic / len(testy)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(121)\n",
    "plt.plot(thresh_array, IoU_array_apl, lw = lw, label='APL', color='darkgreen')\n",
    "plt.plot(thresh_array, IoU_array_basic, lw = lw, label='Basic', color='darkorange')\n",
    "plt.xlabel('Cut-off', fontsize=font_size)\n",
    "plt.ylabel('IoU', fontsize=font_size)\n",
    "plt.legend(fontsize=font_size)\n",
    "#plt.title('Cut-off vs. IoU for Palm')\n",
    "plt.subplot(122)\n",
    "plt.plot(thresh_array, acc_array_apl, lw = lw, label='APL', color='darkgreen')\n",
    "plt.plot(thresh_array, acc_array_basic, lw = lw, label='Basic', color='darkorange')\n",
    "plt.xlabel('Cut-off', fontsize=font_size)\n",
    "plt.ylabel('Accuracy', fontsize=font_size)\n",
    "#plt.title('Threshold vs. Accuracy for Palm')\n",
    "plt.legend(fontsize=font_size)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use selected cut-off, plot scatterplot for IoU vs. Accuracy\n",
    "loc_apl = np.argmax(IoU_array_apl)\n",
    "loc_basic = np.argmax(IoU_array_basic)\n",
    "#print('Thresholds:', thresh_array[loc_apl], thresh_array[loc_basic])\n",
    "#print('F1 score:', f1_score(testy, (probs_apl > thresh_array[loc_apl])), f1_score(testy, (probs_basic > thresh_array[loc_basic])))\n",
    "#print('IoU:', IoU_array_apl[loc_apl], IoU_array_basic[loc_basic])\n",
    "#print('Accuracy:', acc_array_apl[loc_apl], acc_array_basic[loc_basic])\n",
    "scalarmappaple = cm.ScalarMappable(norm=normalize, cmap=colormap)\n",
    "scalarmappaple.set_array([])\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(acc_array_apl[loc_apl], IoU_array_apl[loc_apl], s=150, c='darkgreen', marker='s', label='APL')\n",
    "plt.scatter(acc_array_basic[loc_basic], IoU_array_basic[loc_basic], s=150, c='darkorange', marker='s', label='Basic')\n",
    "plt.scatter(acc_list, IoU_list, s=np.sqrt(nums_list)*3, label='Annotators', c= colormap(normalize(val_list)))\n",
    "plt.xlabel('Accuracy', fontsize=font_size)\n",
    "plt.ylabel('IoU', fontsize=font_size)\n",
    "plt.colorbar(scalarmappaple)\n",
    "plt.tick_params(labelsize=font_size)\n",
    "plt.legend(fontsize=font_size)\n",
    "plt.savefig('../output/figs/palm_IoU.png', bbox_inches='tight')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
